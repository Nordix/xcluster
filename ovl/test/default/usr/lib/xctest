#! /bin/sh
##
## Library functions for tests in "xcluster".
##
##
## On-cluster Functions
## --------------------
##

__timeout=10
__retries=10
__interval=1
begin=$(date +%s)
indent="  "
kubectl=kubectl
sshopt="-o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no"

##  tlog message...
##    Logs to stdout and stderr with time stamp.
tlog() {
	echo "$indent$(date +%T) $*" >&2
	echo "$indent$(date +%T) $*"
}

##  tcase slogan...
##    Initiates a new test-case. The slogan is logged to stderr.
tcase() {
	tcstart=$(date +%s)
	local msg
	if test -n "$indent"; then
		msg="$(date +%T) ($(hostname)): TEST CASE: $*"
	else
		msg="$(date +%T) ($((tcstart-begin))): TEST CASE: $*"
	fi
	echo "$indent$msg"
	echo "$indent$msg" >&2
}

##  tdie [message...]
##    Terminates the test with an error code.
tdie() {
	now=$(date +%s)
	echo "$indent$(date +%T) ($((now-begin))): FAILED: $*" >&2
	rm -rf $tmp
	exit 1
}

##  tex command...
##    Ececute a function with retries and timeout. Ok (0) is returned
##    if succesful. Relevant settings in seconds;
##
##    __timeout (10) - Max time since start of the test case
##    __retries (10) - Max re-tries
##    __interval (1) - Interval between re-tries
##
##    Use "pushv 60 12 5" for instance to set re-try variables.
##
##    If the command includes a redirect it MUST be qouted;
##
##      tex "get-items > /tmp/items" || tdie "Can't get items"
##
tex() {
	local cmd
	cmd="$@"
	echo "tex [$cmd]"
	eval $cmd && return 0
	test $__retries -gt 0 || return 1

	# We shall do retries
	local tstart=$(date +%s)
	local now
	local retry=1
	while test $retry -le $__retries; do
		now=$(date +%s)
		if echo $__interval | grep -qE '^[0-9]+$'; then
			if test $((now+__interval-tstart)) -ge $__timeout; then
				tlog "Timeout ($__timeout)"
				return 2
			fi
		fi
		sleep $__interval
		echo "Retry ($retry/$__retries) [$cmd]"
		eval $cmd && return 0
		retry=$((retry+1))
	done
	return 1
}
##  push variable value
##    Example; "push __timeout 20"
push() {
	eval stack$1="\$$1,\$stack$1"
	eval $1=$2
}
##  pop variable
##    Example; "pop __timeout"
pop() {
	local s=$(eval echo \$stack$1)
	eval $1=$(echo $s | cut -d, -f1)
	eval stack$1=$(echo $s | cut -d, -f2-)
}
##  pushv __timeout [__retries __interval]
##    Combo push. Example; "pushv 60 15 4" or "pushv 60"
pushv() {
	if test -z "$2"; then
		# Only timeout
		local timeout=$1
		push __timeout $timeout
		push __retries $((timeout / 2))
		push __interval 2
		return
	fi
	push __timeout $1
	push __retries $2
	push __interval $3
}
##  popv
##    Pop values pushed with "pushv"
popv() {
	pop __timeout
	pop __retries
	pop __interval
}

##  ogrep
##    Grep and send raw output to stdout (for logging).
ogrep() {
	mkdir -p $tmp
	cat > $tmp/out
	cat $tmp/out
	grep "$@" $tmp/out
}

##  mynode
##    Output the node number.
mynode() {
	hostname | cut -d- -f2 | sed -re 's,^0+,,'
}

##  npods <pattern> <expected-replicas>
##    Returns true if the expected number of pods are "Running",
##    and there are no "Terminating" pods.
##    Example; tex "npods mconnect-deployment- 4" || tdie
npods() {
	local n t
	$kubectl get pods 2>&1 | ogrep 'No resources' && return 1
	if echo "$1" | grep -q '='; then
		# Use a match label
		n=$($kubectl get pods -l $1 | grep "Running" | wc -l)
		t=$($kubectl get pods -l $1 | grep "Terminating" | wc -l)
	else
		n=$($kubectl get pods | grep -E "^$1.*Running" | wc -l)
		t=$($kubectl get pods | grep -E "^$1.*Terminating" | wc -l)
	fi
	test $t -eq 0 || return 1
	test $n -eq $2
}

##  nreplicas <deployment>
##    Print the number of replicas in a Deployment.
nreplicas() {
	$kubectl get deployment $1 > /dev/null || tdie
	$kubectl get deployment $1 -o json | jq -r .spec.replicas
}

##  lsimages
##    Output the images loaded in the system
lsimages() {
	crictl images
}

##  test_namespaces
##    Test (and waits for) the basic namespaces to appear. This should
##    normally be the first test executes on all K8s clusters. Prints versions
##    of central components if succesful.
test_namespaces() {
	local to=60
	test -n "$1" && to=$1
	tcase "Check namespaces (and API-server availability) ($to)"
	pushv $to
	tex "$kubectl get namespace default 2>&1 | ogrep -E '^default *Active'" || tdie	
	tex "$kubectl get namespace kube-system 2>&1 | ogrep -E '^kube-system *Active'" || tdie	
	popv
	log_version
}

##  test_deployment <deployment> [timeout]
##    Verify that all PODs in a deployment are ready
test_deployment() {
	tcase "Checking Deployment [$1]"
	test -n "$1" || tdie "No deployment"
	test -n "$2" && pushv $2
	tex "$kubectl get deployment $1" 2>&1 || tdie "get deployment"
	local replicas=$(nreplicas $1)
	echo "Expected replicas [$replicas]"
	local selector=$($kubectl get deployment $1 -o json | \
		jq -r '.spec.selector.matchLabels|to_entries[0]|.key + "=" + .value')
	echo "POD selector [$selector]"
	tex deployment_nready $1 $replicas || tdie "deployment ready"
	tex "check_pods_ready $selector" || tdie "pods ready"
	test -n "$2" && popv
	return 0
}
deployment_nready() {
	local nready=$($kubectl get deployment $1 -o json | \
		jq -r '.status.readyReplicas')
	test "$nready" = "null" && return 1
	test "$nready" -eq "$2"
}
##  test_daemonset <daemonset> [timeout]
##    Verify that all PODs in a deployment are ready
test_daemonset() {
	mkdir -p $tmp
	local nodes=$(kubectl get nodes -o json | jq '.items|length')
	tcase "Checking DaemonSet [$1] (nodes=$nodes)"
	$kubectl get daemonset $1 -o json > $tmp/out || tdie
	local desired=$(cat $tmp/out | jq -r .status.desiredNumberScheduled)
	# daemonset.status.desiredNumberScheduled=0 for some time in v1.26.0-beta.0
	# https://github.com/kubernetes/kubernetes/issues/113844
	# TODO; This is a hack. re-write the desired/ready tests
	while test $desired -eq 0; do
		echo "Nodes=$nodes, desired=$desired"
		sleep 1
		$kubectl get daemonset $1 -o json > $tmp/out || tdie
		desired=$(cat $tmp/out | jq -r .status.desiredNumberScheduled)
	done
	test $nodes -eq $desired || tlog "Nodes=$nodes but desired=$desired"
	local selector=$(get_selector < $tmp/out)
	test -n "$2" && pushv $2
	tex "daemonset_ready $1" || tdie "Daemonset ready"
	desired=$(cat $tmp/out | jq -r .status.desiredNumberScheduled)
	tex "npods $selector $desired" || tdie "npods"
	tex "check_pods_ready $selector" || tdie "Pods ready"
	test -n "$2" && popv
	return 0	
}
daemonset_ready() {
	$kubectl get daemonset $1 -o json > $tmp/out || tdie
	local desired=$(cat $tmp/out | jq -r .status.desiredNumberScheduled)
	local ready=$(cat $tmp/out | jq -r .status.numberReady)
	echo "DaemonSet [$1], ready=$ready, desired=$desired"
	test $desired -eq $ready
}
get_selector() {
	jq -r '.spec.selector.matchLabels|to_entries[0]|.key + "=" + .value'
}
##  test_statefulset <statefulset> [timeout]
##    Verify that all PODs in a statefulset are ready
test_statefulset() {
	tcase "Check statefulset [$1]"
	local replicas=$($kubectl get statefulset $1 -o json | jq .spec.replicas)
	echo "statefulset $1, replicas $replicas"
	test -n "$2" && pushv $2
	tex "statefulset_ready $1 $replicas"
	test -n "$2" && popv
	return 0	
}
statefulset_ready() {
	local ready=$($kubectl get statefulset $1 -o json | jq .status.readyReplicas)
	test "$ready" = "$2"
}

##  test_nodes
##    Wait for the k8s nodes to become available through the API
test_nodes() {
	# Special case; in k8s-xcluster we can start with only the master
	# and zero workers (nodes==0).
	test -n "$FIRST_WORKER" || FIRST_WORKER=1
	test -n "$__nvm" || __nvm=4
	if test $FIRST_WORKER -gt $__nvm; then
		tcase "No k8s nodes, only master"
		return 0
	fi
	local vm=$(printf "vm-%03d" $FIRST_WORKER)
	tcase "Wait for k8s nodes (first node $vm)"
	pushv 180 60 3
	tex "$kubectl get nodes 2>&1 | ogrep $vm" || tdie
	tex all_nodes_ready || tdie
	popv
}
all_nodes_ready() {
	! kubectl get nodes -o json | \
		jq -r '.items[]|.status.conditions[]|select(.type == "Ready")|.status' \
		| grep -v True
}

##  get_pod <name> [host]
##    Print the pod-id (used for instance for "kubectl exec"). Print "null"
##    if the pod can't be found.
get_pod() {
	local l=$1
	echo $1 | grep -q = || l="app=$1"
	if test -z "$2"; then
		$kubectl -o json get pods -l $l | jq -r .items[0].metadata.name
	else
		$kubectl -o json get pods -l $l | jq -r \
			"[.items[]|select(.spec.nodeName == \"$2\")|.metadata.name]|.[0]"
	fi
}
get_pods() {
	$kubectl -o json get pods -l "$1" | jq -r .items[].metadata.name
}
pod_ready() {
	$kubectl -o json get pod "$1" | jq -r .status.containerStatuses[].ready \
		| ogrep -v true && return 1
	return 0
}
check_pods_ready() {
	local p
	for p in $(get_pods "$1"); do
		pod_ready $p || return 1
	done
	return 0
}

##  kubectl_exec <pod> <kubectl-exec options...>
##    Execute a command in a pod (container).
kubectl_exec() {
	local podid=$(get_pod $1)
	test "$podid" = "null" && tdie "Pod not found [$1]"
	shift
	echo "[$kubectl exec $podid $@]"
	$kubectl exec $podid $@
}

##  check_mconnect_result <file.json> [nconn targets] [margin%]
##    Check the result of an "mconnect".
check_mconnect_result() {
	cat $1 | jq .
	local v
	local nconn=$2; test -n "$nconn" || nconn=100
	local targets=$3; test -n "$targets" || targets=4
	local margin=$4;
	if test -z "$margin"; then
		margin=50
		# Handle proxiers with not-so-good distribution
		test "$PROXY_MODE" = "iptables" && margin=80
		test -r /etc/kubernetes/load/quick-install.yaml && margin=80 #(cilium)
	fi
	local expected=$((nconn / targets))
	test -n "$expected" || expected=25
	local diff max min
	if test $margin -ge 100; then
		min=1
		max=$((expected * 4))
	else
		diff=$((expected * margin / 100))
		max=$((expected + diff))
		min=$((expected - diff))
	fi
	local i=0
	echo "Nconn $nconn, targets $targets, margin $margin%, interval [$min-$max]"
	for v in $(cat $1 | jq -r '.hosts|flatten[]'); do
		i=$((i + 1))
		if test $v -gt $max; then
			echo "Too large [$v]"
			return 1
		fi
		if test $v -lt $min; then
			echo "Too small [$v]"
			return 1
		fi
	done
	if test $i -ne $targets; then
		echo "Expected $targets targets, but got $i"
		return 1
	fi
	return 0
}
##  do_mconnect <address> [nconns] [targets] [margin]
##    Execute an mconnect. Uses global var: $mcopts
do_mconnect() {
	mkdir -p $tmp
	local out=$tmp/out
	local adr=$1
	shift
	local nconn=100
	if test -n "$1"; then
		nconn=$1
		shift
	fi
	if echo $adr | grep -qF ']' ; then
		echo $adr | grep -qF ']:' || adr=$adr:5001
	else
		echo $adr | grep -qF ':' || adr=$adr:5001
	fi
	if ! mconnect -address $adr -nconn $nconn -output json $mcopts > $out; then
		cat $out | jq .
		return 1
	fi
	check_mconnect_result $out $nconn $@
}
##  log_version
##    Log versions of various things
log_version() {
	. /etc/os-release
	test "$VERSION" != "1.0" && tlog "Xcluster: $VERSION"
	tlog "$(uname -s -r -v)"
	which kubectl > /dev/null || return 0
	local ver=$(kubectl version 2> /dev/null | grep Server)
	tlog "$ver"
	tlog "CNI-plugin; $(cni_plugin_info)"
	tlog "Proxy-$(grep mode /etc/kubernetes/kube-proxy.config)"
	if which containerd > /dev/null; then
		ver=$(containerd --version | cut -d' ' -f3)
		tlog "Containerd [$ver]"
	else
		tlog $(crio -v 2> /dev/null | grep "crio version")
	fi
	local baseFamily=IPv4
	ipv6base && baseFamily=IPv6
	tlog "BaseFamily=$baseFamily"
}
cni_plugin_info() {
	if test -n "$CNI_INFO"; then
		echo $CNI_INFO
		return 0
	fi

	local f d=/etc/kubernetes/load

	f=$d/quick-install.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o 'cilium:.*' | tr -d '"' | uniq
		return 0
	fi

	f=$d/calico.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "calico/cni:.*" | uniq
		return 0
	fi

	f=$d/xcluster-cni.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "xcluster-cni:.*"
		return 0
	fi

	f=$d/weave.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "weave-kube:.*" | tr -d "'" | uniq
		return 0
	fi

	f=$d/kube-flannel.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "flannel:.*" | tr -d "'" | uniq
		return 0
	fi

	f=$d/kuberouter.yaml
	if test -r $f; then
		grep '  image:' $f | grep -Eo "kube-router:?.*" | uniq
		return 0
	fi

	f=$d/antrea.yaml
	if test -r $f; then
		grep '  image:' $f | grep -Eo "antrea-.*" | uniq
		return 0
	fi

	if test -r /opt/cni/bin/node-local; then
		echo "xcluster internal"
		return 0
	fi

	echo "Unknown CNI-plugin"
}
##  ipv6base
##    Returns true if the "main" cluster family is ipv6
ipv6base() {
	tex kubectl get svc kubernetes > /dev/null 2>&1
	kubectl get svc -o json kubernetes | jq -r .spec.clusterIP | grep -q :
}
##  apply_k8s <manifest-dir>
##    Applies k8s manifests in the passed dir and in dir/dual.
apply_k8s() {
	tlog "Applying manifests from [$1]"
	test -n "$1" || tdie "No dir"
	test -d "$1" || tdie "Not a directory [$1]"
	local yamld=$1
	$kubectl apply -f $yamld || tdie
	if test -d $yamld/dual; then
		$kubectl apply -f $yamld/dual || tdie
	fi
	return 0
}

##  vip_route
##    Setup ECMP routes to 10.0.0.0/24 $PREFIX:1:10.0.0.0/120
##    (and 1000::/120 for backward compatibility)
vip_route() {
	local net=1
	test -n "$1" && net=$1
	test -n "$PREFIX" || PREFIX=1000::1
	test -n "$FIRST_WORKER" || FIRST_WORKER=1
	local hops4 hops6 i
	for i in $(seq $FIRST_WORKER $__nvm); do
		hops4="$hops4 nexthop via 192.168.$net.$i"
		hops6="$hops6 nexthop via $PREFIX:192.168.$net.$i"
	done
	ip ro replace 10.0.0.0/24 $hops4|| tdie "Ipv4 routes"
	ip -6 ro replace $PREFIX:10.0.0.0/120 $hops6 || tdie "Ipv6 routes"
	ip -6 ro replace 1000::/120 $hops6 || tdie "Ipv6 routes"
}

##
## On-host Functions
## -----------------
## NOTE: Called from host (not within the cluster).
##

##  rsh <vm> command...
##    Executes a command on a vm.
##
rsh() {
	local vm=$1
	shift
	if ip link show xcbr1 > /dev/null 2>&1; then
		ssh -q $sshopt root@192.168.0.$vm $@
	else
		ssh -q $sshopt -p $((12300+vm)) root@127.0.0.1 $@
	fi
}

##  rcp <vm> <remote-file> <local-file>
##    Get a file from a VM.
##
rcp() {
	local vm=$1
	shift
	if ip link show xcbr1 > /dev/null 2>&1; then
		scp -q $sshopt root@192.168.0.$vm:$1 $2
	else
		scp -q $sshopt -P $((12300+vm)) root@127.0.0.1:$1 $2
	fi
}


##  check_vm [vms...]
##    NOTE: Called from host (not within the cluster).
##    Check connectivity with the vm's.
##
check_vm() {
	test -n "$__nvm" || __nvm=4
	test -n "$__nrouters" || __nrouters=2
	local last_router=$((200 + __nrouters))
	test -n "$__ntesters" || __ntesters=0
	local last_tester=$((220 + __ntesters))
	local vms="$(seq -s' ' 1 $__nvm) $(seq 201 $last_router) $(seq 221 $last_tester)"
	test -n "$1" && vms=$@
	for vm in $vms; do
		rsh $vm hostname || return 1
	done
	return 0
}

##  otc <vm> <tcase...>
##    Execute a test on a VM.
##    Prerequisite; "otcprog" set to the command on the cluster.
##  otcw <tcase...>
##    Execute a test on all worker vms.
##  otcwp <tcase...>
##    Execute a test on all worker vms in parallel
##  otcr <tcase...>
##    Execute a test on all routers.
##  otcr <tcase...>
##    Execute a test on all testers.
##
otc() {
	test -n "$otcprog" || otcprog=$(basename $0 .sh)_test
	local tc vm
	vm=$1
	shift
	for tc in "$@"; do
		rsh $vm $otcprog tcase_$tc || tdie
	done
}
otcw() {
	local x
	test -n "$xcluster_FIRST_WORKER" || xcluster_FIRST_WORKER=1
	for x in $(seq $xcluster_FIRST_WORKER $__nvm); do
		otc $x "$@"
	done
}
otcwp() {
	local x
	test -n "$xcluster_FIRST_WORKER" || xcluster_FIRST_WORKER=1
	for x in $(seq $xcluster_FIRST_WORKER $__nvm); do
		(otc $x "$@") &
	done
	for x in $(seq $xcluster_FIRST_WORKER $__nvm); do
		wait || die wait
	done
}
otcr() {
	local x last
	last=$((200 + __nrouters))
	for x in $(seq 201 $last); do
		otc $x "$@"
	done
}
otct() {
	local x last
	last=$((220 + __ntesters))
	for x in $(seq 221 $last); do
		otc $x "$@"
	done
}

##  xcluster_start <ovls...>
##    Build a system (mkcdrom) and start xcluster.
##
xcluster_start() {
	# (mode set for backward compatibility)
	__mode=dual-stack
	export xcluster___mode=$__mode
	test -n "$xcluster_PREFIX" || xcluster_PREFIX=$PREFIX
	test -n "$xcluster_DOMAIN" || xcluster_DOMAIN=xcluster
	export xcluster_DOMAIN xcluster_PREFIX
	test -n "$xcluster_KUBECONFIG" || xcluster_KUBECONFIG=/etc/kubernetes/kubeconfig.token
	export xcluster_KUBECONFIG
	test "$__no_start" = "yes" && return 0
	test -n "$__nvm" || __nvm=4
	test -n "$__nrouters" || __nrouters=2
	test -n "$__ntesters" || __ntesters=0
	export __nvm __nrouters __ntesters	
	if test -n "$SETUP"; then
		tcase "Build cluster SETUP=$SETUP [env $BASEOVLS $@ $XOVLS test]"
		SETUP=$SETUP $XCLUSTER mkcdrom env $BASEOVLS $@ $XOVLS test || tdie
	else
		tcase "Build cluster [env $BASEOVLS $@ $XOVLS test]"
		$XCLUSTER mkcdrom env $BASEOVLS $@ $XOVLS test || tdie
	fi
	tcase "Cluster start ($(basename $__image))"
	if test "$__xterm" = "yes"; then
		$XCLUSTER start || tdie
	else
		$XCLUSTER starts || tdie
	fi
	sleep 2
	local lastrouter=$((200 + __nrouters))
	local lasttester=$((220 + __ntesters))
	local EXPECTED_VMS="$(seq -s' ' 1 $__nvm) $(seq -s' ' 201 $lastrouter) $(seq -s' ' 221 $lasttester)"
	pushv 60 30 2
	tcase "VM connectivity; $EXPECTED_VMS"
	tex check_vm $EXPECTED_VMS || tdie
	popv
}

xcluster_prep() {
	case $1 in
		ipv4)
			tdie "Single-stack not supported (IPv4)"
			;;
		ipv6)
			tdie "Single-stack not supported (IPv6)"
			;;
	esac
	tlog "OBSOLETE function used; xcluster_prep"
}
xcluster_unprep() {
	tlog "OBSOLETE function used; xcluster_unprep"
}

xcluster_stop() {
	test "$__no_stop" = "yes" && return 0
	tcase "Stop xcluster"
	$XCLUSTER stop
}

test -n "$XCTEST_HOOK" -a -r "$XCTEST_HOOK" && . "$XCTEST_HOOK"

test "$1" = "help" && grep '^##' $0 | cut -c3-
