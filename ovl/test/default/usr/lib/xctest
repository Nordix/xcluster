#! /bin/sh
##
## Library functions for tests in "xcluster".
##
##  Perform selftest with;
##    selftest=yes $($XCLUSTER ovld test)/default/usr/lib/xctest
##
## On-cluster Functions
## --------------------
##

__timeout=10
__retries=10
__interval=1
begin=$(date +%s)
indent="  "
kubectl=kubectl
sshopt="-o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no"

##  tlog message...
##    Logs to stdout and stderr with time stamp.
##
tlog() {
	echo "$indent$(date +%T) $*" >&2
	echo "$indent$(date +%T) $*"
}

##  tcase slogan...
##    Initiates a new test-case. The slogan is logged to stderr.
##
tcase() {
	tcstart=$(date +%s)
	local msg
	if test -n "$indent"; then
		msg="$(date +%T) ($(hostname)): TEST CASE: $*"
	else
		msg="$(date +%T) ($((tcstart-begin))): TEST CASE: $*"
	fi
	echo "$indent$msg"
	echo "$indent$msg" >&2
}

##  tdie [message...]
##    Terminates the test with an error code.
##
tdie() {
	now=$(date +%s)
	echo "$indent$(date +%T) ($((now-begin))): FAILED: $*" >&2
	rm -rf $tmp
	exit 1
}

##  tex command...
##    Ececute a function with retries and timeout. Ok (0) is returned
##    if succesful. Relevant settings in seconds;
##
##    __timeout (10) - Max time since start of the test case
##    __retries (10) - Max re-tries
##    __interval (1) - Interval between re-tries
##
##    Use "pushv 60 12 5" for instance to set re-try variables.
##
##    If the command includes a redirect it MUST be qouted;
##
##      tex "get-items > /tmp/items" || tdie "Can't get items"
##
tex() {
	local cmd
	cmd="$@"
	echo "tex [$cmd]"
	eval $cmd && return 0
	test $__retries -gt 0 || return 1

	# We shall do retries
	local tstart=$(date +%s)
	local now
	local retry=1
	while test $retry -le $__retries; do
		now=$(date +%s)
		if echo $__interval | grep -qE '^[0-9]+$'; then
			if test $((now+__interval-tstart)) -ge $__timeout; then
				tlog "Timeout ($__timeout)"
				return 2
			fi
		fi
		sleep $__interval
		echo "Retry ($retry/$__retries) [$cmd]"
		eval $cmd && return 0
		retry=$((retry+1))
	done
	return 1
}

##  push variable value
##    Example; "push __timeout 20"
push() {
	eval stack$1="\$$1,\$stack$1"
	eval $1=$2
}
##  pop variable
##    Example; "pop __timeout"
##
pop() {
	local s=$(eval echo \$stack$1)
	eval $1=$(echo $s | cut -d, -f1)
	eval stack$1=$(echo $s | cut -d, -f2-)
}

##  pushv __timeout __retries __interval
##    Combo push. Example; "pushv 60 15 4"
pushv() {
	if test -z "$2"; then
		# Only timeout
		local timeout=$1
		push __timeout $timeout
		push __retries $((timeout / 2))
		push __interval 2
		return
	fi
	push __timeout $1
	push __retries $2
	push __interval $3
}
##  popv
##    Pop values pushed with "pushv"
##
popv() {
	pop __timeout
	pop __retries
	pop __interval
}

##  ogrep
##    Grep and send raw output to stdout (for logging).
##
ogrep() {
	mkdir -p $tmp
	cat > $tmp/out
	cat $tmp/out
	grep "$@" $tmp/out
}

##  mynode
##    Output the node number.
##
mynode() {
	hostname | cut -d- -f2 | sed -re 's,^0+,,'
}

##  npods <pattern> <expected-replicas>
##    Returns true if the expected number of pods are "Running",
##    and there are no "Terminating" pods.
##    Example; tex "npods mconnect-deployment- 4" || tdie
##
npods() {
	local n t
	$kubectl get pods 2>&1 | ogrep 'No resources' && return 1
	if echo "$1" | grep -q '='; then
		# Use a match label
		n=$($kubectl get pods -l $1 | grep "Running" | wc -l)
		t=$($kubectl get pods -l $1 | grep "Terminating" | wc -l)
	else
		n=$($kubectl get pods | grep -E "^$1.*Running" | wc -l)
		t=$($kubectl get pods | grep -E "^$1.*Terminating" | wc -l)
	fi
	test $t -eq 0 || return 1
	test $n -eq $2
}

##  nreplicas <deployment>
##    Print the number of replicas in a Deployment.
##
nreplicas() {
	$kubectl get deployment $1 > /dev/null || tdie
	$kubectl get deployment $1 -o json | jq -r .spec.replicas
}

##  lsimages
##    Output the images loaded in the system
##
lsimages() {
	crictl --runtime-endpoint=unix:///var/run/crio/crio.sock images
}

##  test_namespaces
##    Test (and waits for) the basic namespaces to appear. This should
##    normally be the first test executes on all K8s clusters. Prints versions
##    of central components if succesful.
##
test_namespaces() {
	local to=60
	test -n "$1" && to=$1
	tcase "Check namespaces (and API-server availability) ($to)"
	pushv $to
	tex "$kubectl get namespace default 2>&1 | ogrep -E '^default *Active'" || tdie	
	tex "$kubectl get namespace kube-system 2>&1 | ogrep -E '^kube-system *Active'" || tdie	
	popv
	log_version
}

##  test_coredns
##    Wait for the coredns pod to become "Running".
##
test_coredns() {
	if test "$__coredns_pod" != "yes"; then
		tcase "SKIPPED; Wait for the coredns pod"
		return 0
	fi
	tcase "Wait for the coredns pod"
	pushv 180 60 3
	tex "$kubectl get pods 2>&1 | ogrep -E '^coredns.*Running'" || tdie
	popv
}

##  test_deployment <deployment> [timeout]
##    Verify that all PODs in a deployment are ready
##
test_deployment() {
	tcase "Checking Deployment [$1]"
	test -n "$1" || tdie "No deployment"
	local replicas=$(nreplicas $1)
	echo "Expected replicas [$replicas]"
	local selector=$($kubectl get deployment $1 -o json | \
		jq -r '.spec.selector.matchLabels|to_entries[0]|.key + "=" + .value')
	echo "POD selector [$selector]"
	test -n "$2" && pushv $2
	tex "npods $selector $replicas" || tdie
	tex "check_pods_ready $selector" || tdie
	test -n "$2" && popv
	return 0
}

##  test_daemonset <daemonset> [timeout]
##    Verify that all PODs in a deployment are ready
##
test_daemonset() {
	mkdir -p $tmp
	local nodes=$(kubectl get nodes -o json | jq '.items|length')
	tcase "Checking DaemonSet [$1] (nodes=$nodes)"
	$kubectl get daemonset $1 -o json > $tmp/out || tdie
	local desired=$(cat $tmp/out | jq -r .status.desiredNumberScheduled)
	test $nodes -eq $desired || tlog "Nodes=$nodes but desired=$desired"
	local selector=$(get_selector < $tmp/out)
	test -n "$2" && pushv $2
	tex "daemonset_ready $1 $desired" || tdie
	tex "npods $selector $desired" || tdie
	tex "check_pods_ready $selector" || tdie
	test -n "$2" && popv
	return 0	
}
daemonset_ready() {
	local ready=$($kubectl get daemonset $1 -o json | jq -r .status.numberReady)
	echo "DaemonSet [$1], ready=$ready"
	test $2 -eq $ready
}
get_selector() {
	jq -r '.spec.selector.matchLabels|to_entries[0]|.key + "=" + .value'
}

##  test_statefulset <statefulset> [timeout]
##    Verify that all PODs in a statefulset are ready
##
test_statefulset() {
	tcase "Check statefulset [$1]"
	local replicas=$($kubectl get statefulset $1 -o json | jq .spec.replicas)
	echo "statefulset $1, replicas $replicas"
	test -n "$2" && pushv $2
	tex "statefulset_ready $1 $replicas"
	test -n "$2" && popv
	return 0	
}
statefulset_ready() {
	local ready=$($kubectl get statefulset $1 -o json | jq .status.readyReplicas)
	test "$ready" = "$2"
}

##  test_nodes
##    Wait for the k8s nodes to become available through the API
##
test_nodes() {
	# Special case; in k8s-xcluster we can start with only the master
	# and zero workers (nodes==0).
	test -n "$FIRST_WORKER" || FIRST_WORKER=1
	test -n "$__nvm" || __nvm=4
	if test $FIRST_WORKER -gt $__nvm; then
		tcase "No k8s nodes, only master"
		return 0
	fi
	local vm=$(printf "vm-%03d" $FIRST_WORKER)
	tcase "Wait for k8s nodes (first node $vm)"
	pushv 180 60 3
	tex "$kubectl get nodes 2>&1 | ogrep $vm" || tdie
	tex all_nodes_ready || tdie
	popv
}
all_nodes_ready() {
	! kubectl get nodes -o json | \
		jq -r '.items[]|.status.conditions[]|select(.type == "Ready")|.status' \
		| grep -v True
}

##  get_pod <name> [host]
##    Print the pod-id (used for instance for "kubectl exec"). Print "null"
##    if the pod can't be found.
##
get_pod() {
	local l=$1
	echo $1 | grep -q = || l="app=$1"
	if test -z "$2"; then
		$kubectl -o json get pods -l $l | jq -r .items[0].metadata.name
	else
		$kubectl -o json get pods -l $l | jq -r \
			"[.items[]|select(.spec.nodeName == \"$2\")|.metadata.name]|.[0]"
	fi
}
get_pods() {
	$kubectl -o json get pods -l "$1" | jq -r .items[].metadata.name
}
pod_ready() {
	$kubectl -o json get pod "$1" | jq -r .status.containerStatuses[].ready \
		| ogrep -v true && return 1
	return 0
}
check_pods_ready() {
	local p
	for p in $(get_pods "$1"); do
		pod_ready $p || return 1
	done
	return 0
}

##  kubectl_exec <pod> <kubectl-exec options...>
##    Execute a command in a pod (container).
##
kubectl_exec() {
	local podid=$(get_pod $1)
	test "$podid" = "null" && tdie "Pod not found [$1]"
	shift
	echo "[$kubectl exec $podid $@]"
	$kubectl exec $podid $@
}

##  start_mconnect <manifest>
##    Starts "mconnect" and wait to 4 replicas become "Running".
##
start_mconnect() {
	tcase "Start mconnect"
	tex "$kubectl apply -f $1" || return 1
	test_deployment mconnect-deployment 60
}

##  check_mconnect_result <file.json>
##    Check the result of an "mconnect". The number of connections must be 100
##    and the number of targets 4.
##
check_mconnect_result() {
	cat $1 | jq .
	local v i=0
	local max=36
	local min=14
	if test "$PROXY_MODE" != "ipvs"; then
		# Handle lousy iptables distribution
		max=50
		min=8
	fi
	for v in $(cat $1 | jq -r '.hosts|flatten[]'); do
		i=$((i + 1))
		test $v -le $max || return 1
		test $v -ge $min || return 1
	done
	test $i -eq 4
}

##  do_mconnect <address>
##    Execute an mconnect.
##
do_mconnect() {
	mkdir -p $tmp
	local out=$tmp/out
	local adr=$1
	shift
	if echo $adr | grep -qF ']' ; then
		echo $adr | grep -qF ']:' || adr=$adr:5001
	else
		echo $adr | grep -qF ':' || adr=$adr:5001
	fi
	if ! mconnect -address $adr -nconn 100 -output json $@ > $out; then
		cat $out | jq .
		return 1
	fi
	check_mconnect_result $out
}


##  log_versions
##    Log versions of various things
##
log_version() {
	. /etc/os-release
	test "$VERSION" != "1.0" && tlog "Xcluster: $VERSION"
	tlog "$(kubectl version --short=true | grep Server)"
	tlog "$(uname -s -r -v)"
	tlog "CNI-plugin; $(cni_plugin_info)"
	tlog "Proxy-$(grep mode /etc/kubernetes/kube-proxy.config)"
	tlog $(crio -v 2> /dev/null | grep "crio version")
	local baseFamily=IPv4
	ipv6base && baseFamily=IPv6
	local dualMode="old dual-stack API"
	isDual3 && dualMode="phase.3 dual-stack API"
	if test "$__mode" = "dual-stack"; then
		if echo "$FEATURE_GATES" | grep -q "IPv6DualStack=false"; then
			tlog "WARNING: __mode=dual-stack but IPv6DualStack=false"
			tlog "Single-stack cluster. BaseFamily=$baseFamily, $dualMode"
		else
			tlog "Dual-stack cluster. BaseFamily=$baseFamily, $dualMode"
		fi
	else
		tlog "Single-stack cluster. BaseFamily=$baseFamily, $dualMode"
	fi
}
cni_plugin_info() {
	if test -n "$CNI_INFO"; then
		echo $CNI_INFO
		return 0
	fi

	local f d=/etc/kubernetes/load

	f=$d/quick-install.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o 'cilium:.*' | tr -d '"' | uniq
		return 0
	fi

	f=$d/calico.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "calico/cni:.*" | uniq
		return 0
	fi

	f=$d/xcluster-cni.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "xcluster-cni:.*"
		return 0
	fi

	f=$d/weave.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "weave-kube:.*" | tr -d "'" | uniq
		return 0
	fi

	f=$d/kube-flannel.yaml
	if test -r $f; then
		grep '  image:' $f | grep -o "flannel:.*" | tr -d "'" | uniq
		return 0
	fi

	f=$d/kuberouter.yaml
	if test -r $f; then
		grep '  image:' $f | grep -Eo "kube-router:?.*" | uniq
		return 0
	fi

	f=$d/antrea.yaml
	if test -r $f; then
		grep '  image:' $f | grep -Eo "antrea-.*" | uniq
		return 0
	fi

	if test -r /opt/cni/bin/node-local; then
		echo "xcluster internal"
		return 0
	fi

	echo "Unknown CNI-plugin"
}

##  isDual
##    Returns true if K8s is dual-stack
##
isDual() {
	echo "$FEATURE_GATES" | grep -q "IPv6DualStack=false" && return 1
	echo "$xcluster_FEATURE_GATES" | grep -q "IPv6DualStack=false" && return 1
	test "$__mode" = "dual-stack"
}
	
##  isDual3
##    Returns true if K8s dual-stack phase.3 is used ("ipFamilies" array).
##
isDual3() {
	test "$(kubectl get svc -o json kubernetes | jq -r .spec.clusterIPs)" != "null"
}

##  ipv6base
##    Returns true if the "main" cluster family is ipv6
##
ipv6base() {
	kubectl get svc -o json kubernetes | jq -r .spec.clusterIP | grep -q :
}

##  apply_k8s <manifest-dir>
##    Applies k8s manifests in the passed dir. If $__mode=dual-stack
##    manifest-dir/dual or manifest-dir/dual-old are also applied
##    depending on "isDual3"
##
apply_k8s() {
	tlog "Applying manifests from [$1]"
	test -n "$1" || tdie "No dir"
	test -d "$1" || tdie "Not a directory [$1]"
	local yamld=$1
	$kubectl apply -f $yamld || tdie

	if isDual; then
		if isDual3; then
			if test -d $yamld/dual; then
				$kubectl apply -f $yamld/dual || tdie
			fi
		else
			if test -d $yamld/dual-old; then
				$kubectl apply -f $yamld/dual-old || tdie
			fi
		fi
	else
		if isDual3 && test -d $yamld/single; then
			$kubectl apply -f $yamld/single || tdie
		fi
	fi
	return 0
}

##  vip_route
##    Setup ECMP routes to 10.0.0.0/24 1000::1:10.0.0.0/120
##    (and 1000::/120 for backward compatibility)
##
vip_route() {
	local net=1
	test -n "$1" && net=$1
	test -n "$PREFIX" || PREFIX=1000::1
	test -n "$FIRST_WORKER" || FIRST_WORKER=1
	local hops4 hops6 i
	for i in $(seq $FIRST_WORKER $__nvm); do
		hops4="$hops4 nexthop via 192.168.$net.$i"
		hops6="$hops6 nexthop via $PREFIX:192.168.$net.$i"
	done
	ip ro replace 10.0.0.0/24 $hops4|| tdie "Ipv4 routes"
	ip -6 ro replace 1000::1:10.0.0.0/120 $hops6 || tdie "Ipv6 routes"
	ip -6 ro replace 1000::/120 $hops6 || tdie "Ipv6 routes"
}


## On-host Functions
## -----------------
## NOTE: Called from host (not within the cluster).
##

##  rsh <vm> command...
##    Executes a command on a vm.
##
rsh() {
	local vm=$1
	shift
	if ip link show xcbr1 > /dev/null 2>&1; then
		ssh -q $sshopt root@192.168.0.$vm $@
	else
		ssh -q $sshopt -p $((12300+vm)) root@127.0.0.1 $@
	fi
}

##  rcp <vm> <remote-file> <local-file>
##    Get a file from a VM.
##
rcp() {
	local vm=$1
	shift
	if ip link show xcbr1 > /dev/null 2>&1; then
		scp -q $sshopt root@192.168.0.$vm:$1 $2
	else
		scp -q $sshopt -P $((12300+vm)) root@127.0.0.1:$1 $2
	fi
}


##  check_vm [vms...]
##    NOTE: Called from host (not within the cluster).
##    Check connectivity with the vm's.
##
check_vm() {
	test -n "$__nvm" || __nvm=4
	test -n "$__nrouters" || __nrouters=2
	local last_router=$((200 + __nrouters))
	test -n "$__ntesters" || __ntesters=0
	local last_tester=$((220 + __ntesters))
	local vms="$(seq -s' ' 1 $__nvm) $(seq 201 $last_router) $(seq 221 $last_tester)"
	test -n "$1" && vms=$@
	for vm in $vms; do
		rsh $vm hostname || return 1
	done
	return 0
}

##  otc <vm> <tcase...>
##    Execute a test on a VM.
##    Prerequisite; "otcprog" set to the command on the cluster.
##  otcw <tcase...>
##    Execute a test on all worker vms.
##  otcr <tcase...>
##    Execute a test on all routers.
##  otcr <tcase...>
##    Execute a test on all testers.
##
otc() {
	test -n "$otcprog" || otcprog=$(basename $dir)_test
	local tc vm
	vm=$1
	shift
	for tc in "$@"; do
		rsh $vm $otcprog tcase_$tc || tdie
	done
}
otcw() {
	local x
	for x in $(seq 1 $__nvm); do
		otc $x "$@"
	done
}
otcr() {
	local x last
	last=$((200 + __nrouters))
	for x in $(seq 201 $last); do
		otc $x "$@"
	done
}
otct() {
	local x last
	last=$((220 + __ntesters))
	for x in $(seq 221 $last); do
		otc $x "$@"
	done
}

##  xcluster_start <ovls...>
##    Build a system (mkcdrom) and start xcluster.
##
xcluster_start() {
	test "$__no_start" = "yes" && return 0
	test -n "$__nvm" || __nvm=4
	test -n "$__nrouters" || __nrouters=2
	test -n "$__ntesters" || __ntesters=0
	export __nvm __nrouters __ntesters	
	if test -n "$SETUP"; then
		tcase "Build cluster SETUP=$SETUP [env $BASEOVLS $@ $XOVLS test]"
		SETUP=$SETUP $XCLUSTER mkcdrom env $BASEOVLS $@ $XOVLS test || tdie
	else
		tcase "Build cluster [env $BASEOVLS $@ $XOVLS test]"
		$XCLUSTER mkcdrom env $BASEOVLS $@ $XOVLS test || tdie
	fi
	tcase "Cluster start ($(basename $__image))"
	$XCLUSTER $start || tdie
	sleep 2
	local lastrouter=$((200 + __nrouters))
	local lasttester=$((220 + __ntesters))
	local EXPECTED_VMS="$(seq -s' ' 1 $__nvm) $(seq -s' ' 201 $lastrouter) $(seq -s' ' 221 $lasttester)"
	pushv 60 30 2
	tcase "VM connectivity; $EXPECTED_VMS"
	tex check_vm $EXPECTED_VMS || tdie
	popv
	xcluster_unprep
}

##  xcluster_prep <ipv4|ipv6|dual-stack|...>
##    Set SETUP and BASEOVLS variables for some pre-set configurations.
##
xcluster_prep() {
	# NOTE!!!!!
	# Update ovl/k8s-xcluster/xctest-hook when this function is updated!!
	case $1 in
		ipv4)
			SETUP="ipv4,$XSETUP"
			BASEOVLS=kubernetes
			;;
		ipv6)
			SETUP="ipv6,$XSETUP"
			BASEOVLS=kubernetes
			;;
		*)
			SETUP=$XSETUP
			__mode=dual-stack
			;;
	esac
	export xcluster___mode=$1
	test -n "$xcluster_DOMAIN" || xcluster_DOMAIN=xcluster
	export xcluster_DOMAIN
	test -n "$xcluster_KUBECONFIG" || xcluster_KUBECONFIG=/etc/kubernetes/kubeconfig.token
	export xcluster_KUBECONFIG
}
xcluster_unprep() {
	unset SETUP BASEOVLS 
}

xcluster_stop() {
	test "$__no_stop" = "yes" && return 0
	tcase "Stop xcluster"
	$XCLUSTER stop
}

test -n "$XCTEST_HOOK" -a -r "$XCTEST_HOOK" && . "$XCTEST_HOOK"

test "$1" = "help" && grep '^##' $0 | cut -c3-
